{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (20000, 32, 32, 3)\n",
      "[6 9 9 4 1]\n",
      "new x_train shape: (20000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# pytorch\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train) = pickle.load(open('../data/big_cifar_data.pkl', 'rb'))\n",
    "y_train = y_train.flatten()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(y_train[:5])\n",
    "\n",
    "y_train = y_train.astype('int64')  # for long tensor\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train / 127.5\n",
    "x_train = x_train - 1\n",
    "# change shape for pytorch\n",
    "x_train = np.transpose(x_train, [0, 3, 2, 1])\n",
    "print('new x_train shape:', x_train.shape)\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "test_cnt = int(len(x_train) * 0.2)\n",
    "x_test = x_train[:test_cnt]\n",
    "y_test = y_train[:test_cnt]\n",
    "x_train = x_train[test_cnt:]\n",
    "y_train = y_train[test_cnt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      " -0.3255 -0.3333 -0.3098  ...  -0.4353 -0.3882 -0.3569\n",
      " -0.3882 -0.4745 -0.4353  ...  -0.4431 -0.3961 -0.3647\n",
      " -0.5608 -0.7255 -0.6627  ...  -0.4431 -0.4275 -0.3882\n",
      "           ...             ⋱             ...          \n",
      " -0.4824 -0.4588 -0.4431  ...  -0.4667 -0.4275 -0.4118\n",
      " -0.5059 -0.4902 -0.4510  ...  -0.4039 -0.4118 -0.4196\n",
      " -0.5059 -0.4902 -0.4588  ...  -0.4118 -0.4118 -0.4118\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.0824  0.1059  0.1059  ...   0.0118  0.0510  0.0667\n",
      " -0.0902 -0.2392 -0.1686  ...   0.0039  0.0275  0.0510\n",
      " -0.4039 -0.7490 -0.6706  ...  -0.0039  0.0039  0.0275\n",
      "           ...             ⋱             ...          \n",
      " -0.0980 -0.0745 -0.0588  ...  -0.0510 -0.0353 -0.0353\n",
      " -0.1294 -0.1059 -0.0667  ...  -0.0588 -0.0431 -0.0353\n",
      " -0.1216 -0.1059 -0.0745  ...  -0.0510 -0.0353 -0.0353\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.4039  0.3882  0.4510  ...   0.3333  0.3961  0.4275\n",
      "  0.1529 -0.0275  0.0824  ...   0.3176  0.3804  0.4118\n",
      " -0.2549 -0.6784 -0.6157  ...   0.3176  0.3490  0.3882\n",
      "           ...             ⋱             ...          \n",
      "  0.2157  0.2392  0.2549  ...   0.2549  0.2784  0.2784\n",
      "  0.1843  0.2078  0.2471  ...   0.2235  0.2627  0.2706\n",
      "  0.1922  0.2078  0.2471  ...   0.2627  0.2784  0.2784\n",
      "[torch.FloatTensor of size 3x32x32]\n",
      "\n",
      "\n",
      " 5\n",
      " 8\n",
      " 5\n",
      " 8\n",
      " 5\n",
      "[torch.LongTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(2304, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.dropout(out, p=0.25)\n",
    "\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.dropout(out, p=0.25)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "net = CNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(net.parameters(),lr=0.001)\n",
    "\n",
    "x_test = Variable(x_test, volatile=True)\n",
    "y_test = Variable(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "time cost 90.5453 train loss 1.9968 train acc 0.2726\n",
      "test loss 1.5906\n",
      "------------------------\n",
      "epoch 2\n",
      "time cost 87.5565 train loss 1.5466 train acc 0.439\n",
      "test loss 1.4391\n",
      "------------------------\n",
      "epoch 3\n",
      "time cost 87.8907 train loss 1.3626 train acc 0.5074\n",
      "test loss 1.2535\n",
      "------------------------\n",
      "epoch 4\n",
      "time cost 94.6281 train loss 1.2059 train acc 0.5652\n",
      "test loss 1.1703\n",
      "------------------------\n",
      "epoch 5\n",
      "time cost 88.5188 train loss 1.0664 train acc 0.6184\n",
      "test loss 1.1187\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for i in range(epochs):\n",
    "    print(\"epoch\", i + 1)\n",
    "    net.train()\n",
    "    net.float()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_t = time.time()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    # cal test loss\n",
    "    net.eval()\n",
    "    test_out = net(x_test)\n",
    "    test_loss = criterion(test_out, y_test).data[0]\n",
    "\n",
    "    end_t = time.time()\n",
    "    time_cost = end_t - start_t\n",
    "    time_cost = round(time_cost, 4)\n",
    "\n",
    "    train_acc = round(1.0 * correct / total, 4)\n",
    "    train_loss = train_loss / (batch_idx + 1)\n",
    "\n",
    "    print(\"time cost\", time_cost, \"train loss\", round(train_loss, 4), \"train acc\", train_acc)\n",
    "    print(\"test loss\", round(test_loss, 4))\n",
    "    print(\"------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
